{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96aed65-125a-4489-8c08-622e99d0ca60",
   "metadata": {},
   "source": [
    "# Who has a voice in the media?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb7cc0-60c0-45c3-8c11-10233b200116",
   "metadata": {},
   "source": [
    "## 1. Pre-processing the dataset\n",
    "To start with, we remove the rows of the dataset where either the author or the quotation is NaN. As our whole analysis of \"who has a voice in the media\" is all about the speaker and what it has said, it makes no sense to take these rows into account.\n",
    "\n",
    "Later, we also do a sanity controll and remove possible duplicate of rows with the same quote-ID as we obiously don't want to use exactly the same quote more than once in our analyzes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dad80c-8f67-4e37-b510-53d1fa626c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb55ef4-d700-4c3a-86e6-27ea2af192c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(chunk):\n",
    "    \n",
    "    # Drop duplicate quoteIDs\n",
    "    nr_rows = chunk.shape[0]\n",
    "    chunk = chunk.drop_duplicates(subset=['quoteID'])\n",
    "    print('- Dropped {} duplicate rows with same quoteID;'.format(nr_rows - chunk.shape[0]))\n",
    "    \n",
    "    # Drop quotes where either speaker or quotation is None\n",
    "    nr_rows = chunk.shape[0]\n",
    "    chunk.replace(to_replace=['None'], value=np.nan, inplace=True)\n",
    "    chunk = chunk.dropna(axis=0, subset=['speaker', 'quotation'])\n",
    "    print('- Dropped {} rows with NaN speaker or quotation;'.format(nr_rows - chunk.shape[0]))\n",
    "\n",
    "    return chunk\n",
    "\n",
    "start_of_all = timer()\n",
    "with pd.read_json('data/quotes-2020.json.bz2', lines=True, compression='bz2', chunksize=500_000) as df_reader:\n",
    "    print('Started to process chunks...')\n",
    "    i = 0\n",
    "    for chunk in df_reader:\n",
    "        if i > 4:\n",
    "            break\n",
    "        print('\\nProcessing new chunk...')\n",
    "        start = timer()\n",
    "        processed_chunk = clean_data(chunk)\n",
    "        #chunk_list.append(processed_chunk)\n",
    "        processed_chunk.to_csv(path_or_buf='data/clean-quotes-2020-2.bz2', compression='bz2', mode='a')\n",
    "        end = timer()\n",
    "        print('Done processing and saving chunk after {:.3f} seconds.'.format(end - start))\n",
    "        \n",
    "end_of_all = timer()\n",
    "print('Done processing all chunks and saving as csv after {:.3f} minutes.'.format((end_of_all - start_of_all) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0db18f-05a9-49e2-996d-cfbb76367b0b",
   "metadata": {},
   "source": [
    "#### Short discussion\n",
    "Around one third of the dataset seems to have either a NaN speaker or quotation field. We should rethink if there is a way to use this data despite of missing speaker or quotation fields.\n",
    "\n",
    "Elsemore, it seems like there are no duplicates of quote-IDs in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c942ebc-3002-4b31-aeab-a1a3c7a47ea9",
   "metadata": {},
   "source": [
    "## 2. Initial analyzes\n",
    "Here, we do initial studies on the dataset. For instance we plot the following information about the speakers:\n",
    "- gender;\n",
    "- age;\n",
    "- ethnicity;\n",
    "- profession.\n",
    "\n",
    "Also, we do analyzes on the content of the quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29efc634-d3e0-432a-995f-009f55320790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of males and females\n",
    "# profession\n",
    "# age\n",
    "# ethnicity\n",
    "# clean if person has several references in wikidata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a93dcf-240f-4470-b976-e6cfe168fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean-quotes-2020.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4fde0-aa74-47ed-adb8-388792b6dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
